{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import rasterio\n",
    "from rasterio.plot import reshape_as_image\n",
    "import rasterio.mask\n",
    "from rasterio.features import rasterize\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping, Point, Polygon\n",
    "from shapely.ops import cascaded_union\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from geopandas import GeoSeries\n",
    "from shapely.geometry import Polygon\n",
    "from rasterio.windows import Window\n",
    "from rasterio.plot import reshape_as_image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, Flatten, Dense\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the labels dataframe\n",
    "farmpin_data = pd.read_csv(\"/home/ymi/data/ucu_data/Farmpin_training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all images\n",
    "dataset = os.listdir(\"/home/ymi/data/ucu_data/images_cropped_rgb\")\n",
    "farmIds = [int(img_name.split(\".\")[0]) for img_name in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "for num, row in farmpin_data.iterrows():\n",
    "    img_path = os.path.join(\"/home/ymi/data/ucu_data/images_cropped_rgb\", str(row['field_id']) + \".png\")\n",
    "    img = cv2.imread(img_path)\n",
    "    if isinstance(img, np.ndarray):\n",
    "        farmpin_data.loc[num, 'img_path'] = img_path\n",
    "        farmpin_data.loc[num, 'size'] = img.shape[0] * img.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter fields with area higher than 15 pixels \n",
    "\n",
    "farmpin_data.dropna(inplace=True)\n",
    "\n",
    "farmpin_data['size'].min()\n",
    "\n",
    "farmpin_data = farmpin_data[farmpin_data['size'] >= 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare y labels\n",
    "farmpin_data['crop_id'] = farmpin_data['crop_id'] - 1\n",
    "\n",
    "y = to_categorical(farmpin_data['crop_id'].tolist(), num_classes = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path):\n",
    "      \n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(image, w, h):\n",
    "    center = np.array(image.shape) / 2\n",
    "    x = int(center[1] - w/2)\n",
    "    y = int(center[0] - h/2)\n",
    "    crop_img = image[int(y):int(y+h), int(x):int(x+w), :]\n",
    "    return crop_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate X\n",
    "def generate_X(img_list, w, h):\n",
    "    input_size = int(w * h * 3)\n",
    "    X = np.empty((len(img_list), input_size))\n",
    "\n",
    "    for i, item in enumerate(img_list):\n",
    "        img = load_image(item)\n",
    "        # print(img.shape)\n",
    "        if img.shape[0] > h and img.shape[1] > h:\n",
    "            img = crop_image(img, w, h)\n",
    "        img = img.flatten()\n",
    "        if img.shape[0] > input_size:\n",
    "            img = img[:input_size]\n",
    "        X[i,] = img\n",
    "    \n",
    "    # normalize \n",
    "    X = X / 127.5\n",
    "    X -= 1.0\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = generate_X(farmpin_data['img_path'], 4, 4)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_dense(input_shape, num_classes):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # 32 layers with sigmoid activation\n",
    "    # 16 layers\n",
    "    # output with softmax activation\n",
    "    hidden_1 = Dense(32, activation = 'relu')(inputs)\n",
    "    hidden_2 = Dense(16, activation = 'relu')(hidden_1)\n",
    "    outputs = Dense(num_classes, activation = 'softmax')(hidden_2)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model with input 48 and output 9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check model summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_checkpoint = ModelCheckpoint(\"model_class.hdf5\", save_best_only=True, verbose=1, monitor='accuracy', mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model with tf.keras.optimizers.Adam(0.001), loss tf.keras.losses.CategoricalCrossentropy(from_logits=False), tf.keras.metrics.CategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit model\n",
    "classification_model.fit(X_train,\n",
    "          y,\n",
    "          batch_size=256, \n",
    "          epochs=1000,\n",
    "          verbose=1,\n",
    "          callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(farmpin_data['crop_id'].tolist(), np.argmax(y_pred, axis=1))\n",
    "sns.heatmap(conf_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task create train, val, test split \n",
    "# train model with X_train, y_train, X_val, y_val\n",
    "# and predict on X_test, y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
