{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import rasterio\n",
    "from rasterio.plot import reshape_as_image\n",
    "import rasterio.mask\n",
    "from rasterio.features import rasterize\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping, Point, Polygon\n",
    "from shapely.ops import cascaded_union\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from geopandas import GeoSeries\n",
    "from shapely.geometry import Polygon\n",
    "from rasterio.windows import Window\n",
    "from rasterio.plot import reshape_as_image\n",
    "# import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = '/home/ymi/data/ucu_data'\n",
    "\n",
    "RASTER_PATH = os.path.join(PROJECT_DIR, 'T34JEP_20170101T082332/T34JEP_20170101T082332_TCI.jp2')\n",
    "TRAIN_POLYGONS_PATH = os.path.join(PROJECT_DIR, 'train-20220726T194123Z-001/train/train.shp')\n",
    "TEST_POLYGONS_PATH = os.path.join(PROJECT_DIR, 'train-20220726T194123Z-001/test/test.shp')\n",
    "TRAIN_POLYGONS_CONVERTED = os.path.join(PROJECT_DIR, 'train-20220726T194123Z-001/train/train.geojson')\n",
    "RASTER_MASK_PATH = os.path.join(PROJECT_DIR, 'mask.jp2')\n",
    "DROP_CSV_PATH = os.path.join(PROJECT_DIR, 'drop.csv')\n",
    "FRAGMENT_STORAGE = os.path.join(PROJECT_DIR, 'split')\n",
    "CROPPED_IMAGES = os.path.join(PROJECT_DIR, 'images_cropped_rgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading Raster with rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dropped csv \n",
    "drop_df = pd.read_csv(DROP_CSV_PATH)\n",
    "drop_list = drop_df['images_to_drop'].str.split(\"/\").str[-1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get num of dropped masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masks and images paths\n",
    "imgs_path = os.path.join(FRAGMENT_STORAGE, 'images')\n",
    "masks_path = os.path.join(FRAGMENT_STORAGE, 'masks')\n",
    "\n",
    "# only used masks \n",
    "mask_names = os.listdir(masks_path)\n",
    "used_masks = [mask_name for mask_name in mask_names if mask_name not in drop_list]\n",
    "\n",
    "# only used images\n",
    "used_image_names = [os.path.join(imgs_path, mask_name.replace( \"mask_\", \"T34JEP_20170101T082332_TCI_\")) for mask_name in used_masks]\n",
    "used_masks = [os.path.join(masks_path, img_path) for img_path in used_masks]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unet architecture\n",
    "\n",
    "![title](unet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    'build unet model from scratch'\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    \n",
    "    outputs = Conv2D(1, (1,1), activation = 'sigmoid')(conv9)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add early stopping and model save\n",
    "early_stopping = EarlyStopping(patience=5, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(\"model4.hdf5\", save_best_only=True, verbose=1, monitor='dice_coef', mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image and mask\n",
    "def load_image(img_path):\n",
    "      \n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    return img\n",
    "\n",
    "def load_mask(img_path):\n",
    "      \n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img[img>1]=1\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate X\n",
    "def generate_X(img_list):\n",
    "    X = np.empty((len(img_list), 256, 256, 3))\n",
    "\n",
    "    for i, item in enumerate(img_list):\n",
    "        img = load_image(item)\n",
    "        X[i,] = img\n",
    "\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate Y\n",
    "def generate_y(mask_list):\n",
    "    y = np.empty((len(mask_list), 256, 256, 1), dtype=int)\n",
    "\n",
    "    for i, item in enumerate(mask_list):\n",
    "        mask = load_mask(item)\n",
    "        y[i, :, : , 0] = mask\n",
    "    \n",
    "    \n",
    "    return y.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and metrics\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return 0.2 * binary_crossentropy(y_true, y_pred) + 0.8 * dice_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model with (256, 256, 3) input \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(optimizer=Adam(learning_rate = 1e-4),\n",
    "              loss=bce_dice_loss,\n",
    "              metrics=[dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run train\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          batch_size=8, \n",
    "          epochs=25,\n",
    "          verbose=1,\n",
    "          callbacks=[early_stopping,\n",
    "                     model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from disk need to add custom objects bce_dice_loss and dice_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# take some random image from training \n",
    "z = X_train[0].reshape((1,256,256,3))\n",
    "\n",
    "# predict \n",
    "\n",
    "# binarize prediction\n",
    "\n",
    "\n",
    "# plot the results with matplotlib\n",
    "f, axarr = plt.subplots(1, 3)\n",
    "f.set_size_inches(15, 15)\n",
    "axarr[0].imshow(y_train[0].reshape((256,256)))\n",
    "axarr[1].imshow(test.reshape((256,256)))\n",
    "axarr[2].imshow(X_train[0].astype(np.uint8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
